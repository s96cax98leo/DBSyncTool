# Kafka Consumer Properties (for extraction commands)
spring.kafka.consumer.bootstrap-servers=localhost:9092
spring.kafka.consumer.group-id=extract-service-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=com.yt.etl.common.model,java.util,java.lang
spring.kafka.consumer.properties.spring.json.value.defaultType=com.yt.etl.common.model.DataRecordBatch

# Kafka Producer Properties (for untransformed data and status updates)
spring.kafka.producer.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
# producer.properties.spring.json.add.type.headers=false # default is true, which is better for JobStatusUpdate that might be consumed by different groups

# Application Specific Topic Names
etl.topics.command.extract=extraction-commands-topic
etl.topics.output.untransformed=untransformed-data-topic
etl.topics.status.updates=etl-job-status-updates-topic

# Data Extraction properties
etl.extract.batchSize=1000 # Default batch size for reading from source DB

# Logging
logging.level.com.yt.etl.extract=INFO
logging.level.org.springframework.kafka=INFO
logging.level.org.apache.kafka=WARN

# Default Spring Boot Actuator endpoints
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.show-details=always
management.metrics.tags.application=${spring.application.name}

# Spring Application Name
spring.application.name=etl-extract-service
